import fileinput, re, os, sys, zipfile

preamble = '''// `unicode-ideographset` data tables
//
// Licensed under the Apache License, Version 2.0 <LICENSE-APACHE or
// http://www.apache.org/licenses/LICENSE-2.0> or the MIT license
// <LICENSE-MIT or http://opensource.org/licenses/MIT>, at your
// option. This file may not be copied, modified, or distributed
// except according to those terms.

// NOTE: The following code was generated by "scripts/unicode.py", do not edit directly

#![allow(missing_docs, non_upper_case_globals, non_snake_case)]
'''

UNICODE_VERSION = (15, 1, 0)

UNICODE_VERSION_NUMBER = "%s.%s.%s" %UNICODE_VERSION

def fetch(f):
    if not os.path.exists(os.path.basename(f)):
        os.system("curl -O https://www.unicode.org/Public/%s/ucd/%s"
                  % (UNICODE_VERSION_NUMBER, f))

    if not os.path.exists(os.path.basename(f)):
        sys.stderr.write("cannot load %s\n" % f)
        exit(1)

def fetch_unihan(f):
    unihan_zip = "Unihan.zip"
    fetch(unihan_zip)

    if not os.path.exists(os.path.basename(f)):
        with zipfile.ZipFile(unihan_zip) as zip:
            zip.extract(f)

    if not os.path.exists(os.path.basename(f)):
        sys.stderr.write("cannot load %s\n" % f)
        exit(1)

def build_props(f, has_hash = True, prop_filter = None):
    props = {}
    if has_hash:
        re1 = re.compile(r"^ *([0-9A-F]+) *; *([^#]+) *#")
        re2 = re.compile(r"^ *([0-9A-F]+)\.\.([0-9A-F]+) *; *([^#]+) *#")
    else:
        re1 = re.compile(r"^ *([0-9A-F]+) *; *([^#]+)")
        re2 = re.compile(r"^ *([0-9A-F]+)\.\.([0-9A-F]+) *; *([^#]+)")

    for line in fileinput.input(os.path.basename(f), openhook=fileinput.hook_encoded("utf-8")):
        prop = None
        d_lo = 0
        d_hi = 0
        m = re1.match(line)
        if m:
            d_lo = m.group(1)
            d_hi = m.group(1)
            prop = m.group(2).strip()
        else:
            m = re2.match(line)
            if m:
                d_lo = m.group(1)
                d_hi = m.group(2)
                prop = m.group(3).strip()
            else:
                continue
        if prop_filter != None and not prop_filter(prop):
            continue
        d_lo = int(d_lo, 16)
        d_hi = int(d_hi, 16)
        if prop not in props:
            props[prop] = []
        props[prop].append((d_lo, d_hi))
    return props

def build_props_unihan_dict(f, prop_item_expected, prop_item_replacement = None, prop_item_cb = None):
    props = {}
    re1 = re.compile("^U\\+*([0-9A-F]+)[ \\t]*([A-Za-z_0-9]+)[ \\t]*(.*)")
    for line in fileinput.input(os.path.basename(f), openhook=fileinput.hook_encoded("utf-8")):
        m = re1.match(line)
        if not m:
            continue
        line_cp = m.group(1)
        line_prop_item = m.group(2).strip()
        line_prop_value = m.group(3).strip()
        if not line_prop_item == prop_item_expected:
            continue
        line_cp = int(line_cp, 16)
        if prop_item_cb != None:
            prop = prop_item_cb(line_prop_value, line_prop_item, line_cp)
        else:
            prop = prop_item_replacement
        if not prop:
            continue
        if prop not in props:
            props[prop] = []
        if len(props[prop]) == 0 or props[prop][-1][1] + 1 != line_cp:
            props[prop].append((line_cp, line_cp))
        else:
            props[prop][-1] = (props[prop][-1][0], line_cp)
    return props

max_codepoint = 0x10FFFF

def flatten_props_to_table(props, gap_prop = ''):
    prop_list = list(props.keys())
    prop_count = len(prop_list)
    subrange_count = [len(props[key]) for key in prop_list]
    subrange_iter = [0 for _ in prop_list]
    prev_prop_id = -1
    cur_codepoint = 0
    table = []
    # print(props)
    while cur_codepoint <= max_codepoint:
        # print("DBG: U+%04X" % cur_codepoint)
        cur_prop_id = -1
        for prop_id in range(prop_count):
            subrange_id = subrange_iter[prop_id]
            if subrange_id >= subrange_count[prop_id]:
                continue
            prop_value = props[prop_list[prop_id]]
            assert(prop_value[subrange_id][0] >= cur_codepoint)
            if prop_value[subrange_id][0] == cur_codepoint:
                cur_prop_id = prop_id
                break
        if cur_prop_id == -1:
            cur_gap_end = max_codepoint
            for prop_id in range(prop_count):
                if subrange_iter[prop_id] >= subrange_count[prop_id]:
                    continue
                assert(props[prop_list[prop_id]][subrange_iter[prop_id]][0] > cur_codepoint)
                prop_gap_end = props[prop_list[prop_id]][subrange_iter[prop_id]][0] - 1
                if prop_gap_end < cur_gap_end:
                    cur_gap_end = prop_gap_end
            table.append(((cur_codepoint, cur_gap_end), gap_prop))
            cur_codepoint = cur_gap_end + 1
            # print("DBG: %s => U+%04X" % ("GAP", cur_codepoint))
            prev_prop_id = -1
            continue
        cur_subrange_id = subrange_iter[cur_prop_id]
        cur_prop = prop_list[cur_prop_id]
        cur_subrange = props[cur_prop][cur_subrange_id]
        if prev_prop_id != cur_prop_id:
            table.append((cur_subrange, cur_prop))
        else:
            table[-1] = ((table[-1][0][0], cur_subrange[1]), cur_prop)
        cur_codepoint = cur_subrange[1] + 1
        # print("DBG: %s => U+%04X" % (cur_prop, cur_codepoint))
        prev_prop_id = cur_prop_id
        subrange_iter[cur_prop_id] += 1
    return table

def merge_tables(table_list, prop_cb):
    table_count = len(table_list)
    subrange_count = [len(table_list[table_id]) for table_id in range(table_count)]
    subrange_iter = [0 for _ in range(table_count)]
    cur_codepoint = 0
    table = []
    # print(props)
    while cur_codepoint <= max_codepoint:
        # print("DBG: U+%04X" % cur_codepoint)
        cur_range_end = max_codepoint + 1
        prop_list = []
        for table_id in range(table_count):
            assert(subrange_iter[table_id] < subrange_count[table_id])
            assert(table_list[table_id][subrange_iter[table_id]][0][0] <= cur_codepoint)
            table_range_end = table_list[table_id][subrange_iter[table_id]][0][1]
            if table_range_end < cur_range_end:
                cur_range_end = table_range_end
            prop_list.append(table_list[table_id][subrange_iter[table_id]][1])
        if cur_range_end > max_codepoint:
            break
        code_range = (cur_codepoint, cur_range_end)
        prop = prop_cb(prop_list, code_range)
        table.append((code_range, prop))
        for table_id in range(table_count):
            if table_list[table_id][subrange_iter[table_id]][0][1] == cur_range_end:
                subrange_iter[table_id] += 1
        cur_codepoint = cur_range_end + 1
    return table

def choose_either(prop_list, _):
    [prop1, prop2] = prop_list
    if prop1 == '' and prop2 == '':
        return ''
    elif prop1 == '':
        return prop2
    elif prop2 == '':
        return prop1
    else:
        assert prop1 == prop2
        return prop1

def load_gb0_table():
    f = "Unihan_OtherMappings.txt"
    fetch_unihan(f)
    def take_gb0_level(val: str, _1, _2):
        group = int(val[:2])
        if group < 56:
            return 'GB0L1'
        else:
            return 'GB0L2'
    props = build_props_unihan_dict(f, "kGB0", None, take_gb0_level)
    table = flatten_props_to_table(props)
    return table

def load_gbsuppl1_table():
    f1 = "Unihan_OtherMappings.txt"
    fetch_unihan(f1)
    props1 = build_props_unihan_dict(f1, "kGB1", "GBSuppl1")
    table1 = flatten_props_to_table(props1)
    f2 = "Unihan_IRGSources.txt"
    fetch_unihan(f2)
    def take_gsource_g1(val: str, _, code):
        if val.startswith('G1-'):
            return 'GBSuppl1'
        else:
            return None
    props2 = build_props_unihan_dict(f2, "kIRG_GSource", None, take_gsource_g1)
    table2 = flatten_props_to_table(props2)
    table = merge_tables([table1, table2], choose_either)
    return table

def load_gbsuppl3_table():
    f = "Unihan_OtherMappings.txt"
    fetch_unihan(f)
    props = build_props_unihan_dict(f, "kGB3", "GBSuppl3")
    table = flatten_props_to_table(props)
    return table

def load_gbsuppl5_table():
    f = "Unihan_OtherMappings.txt"
    fetch_unihan(f)
    props = build_props_unihan_dict(f, "kGB5", "GBSuppl5")
    table = flatten_props_to_table(props)
    return table

def load_gbsupplfictional6_table():
    f = "Unihan_IRGSources.txt"
    fetch_unihan(f)
    def take_gsource_gk_and_gx(val: str, _, code):
        if code >= 0x4e00 and code <= 0x9fa5:
            pass
        else:
            return None
        if val.startswith('GK-'):
            return 'GBSupplFictional6GK'
        elif val.startswith('GH-'):
            return 'GBSupplFictional6GH'
        elif val.startswith('GU-'):
            return 'GBSupplFictional6GU'
        elif val.startswith('GT-'):
            return 'GBSupplFictional6GT'
        elif val.startswith('G7-'):
            return 'GBSupplFictional6G7'
        elif val.startswith('G8-'):
            return 'GBSupplFictional6G8'
        elif val.startswith('GHZ-'):
            return 'GBSupplFictional6GHZ'
#        elif val.startswith('GKJ-'):
#            return 'GBSupplFictional6GKJ'
#        elif val.startswith('GLK-'):
#            return 'GBSupplFictional6GLK'
#        elif val.startswith('GHZR-'):
#            return 'GBSupplFictional6GHZR'
#        elif val.startswith('GZFY-'):
#            return 'GBSupplFictional6GZFY'
        else:
            return None
    props = build_props_unihan_dict(f, "kIRG_GSource", None, take_gsource_gk_and_gx)
    table = flatten_props_to_table(props)
    return table

def load_gbsuppl7_table():
    f = "Unihan_IRGSources.txt"
    fetch_unihan(f)
    def take_gsource_ge(val: str, _1, _2):
        if val.startswith('GE-'):
            return 'GBSuppl7'
        else:
            return None
    props1 = build_props_unihan_dict(f, "kIRG_GSource", None, take_gsource_ge)
    # This is almost correct though NOT reliable method
    # because GSource contains single value for each code point
    # and `GE-` might not be the preferred source.

    # The correct count should be 3778.
    # With Unicode 15.0 data file, this methods retrieves 3772.
    # FIXME: find out and add the remaining six
    table1 = flatten_props_to_table(props1)
    props2 = {'GBSuppl7': [(0x6FF9, 0x6FF9), (0x809E, 0x809E), (0x891D, 0x891D),
                           (0x925D, 0x925D), (0x943D, 0x943D), (0x946A, 0x946A)]}
    table2 = flatten_props_to_table(props2)
    table = merge_tables([table1, table2], choose_either)
    return table

def load_sjsuppl8_table():
    props = {}
    # FIXME:
    table = flatten_props_to_table(props)
    return table

def make_gbset_name(prop_list, code_range):
    [gb0, gbsuppl1, gbsuppl3, gbsuppl5, gbsuppl6, gbsuppl7, sjsuppl8] = prop_list
    if gb0 != '':
        assert gbsuppl1 == '' or gbsuppl3 == ''
        assert gbsuppl5 == ''
        assert gbsuppl6 == ''
        assert gbsuppl7 == ''
        assert sjsuppl8 == ''
        if gbsuppl1 != '':
            return gb0 + 'AndSuppl1'
        elif gbsuppl3 != '':
            return gb0 + 'AndSuppl3'
        return gb0
    elif gbsuppl1 != '':
        assert gbsuppl3 == ''
        assert gbsuppl5 == ''
        assert gbsuppl6 == ''
        assert gbsuppl7 == ''
        assert sjsuppl8 == ''
        return 'GBSuppl1'
    elif gbsuppl3 != '':
        assert gbsuppl5 == ''
        assert gbsuppl6 == ''
        assert gbsuppl7 == ''
        assert sjsuppl8 == ''
        return 'GBSuppl3'    
    elif gbsuppl5 != '':
        assert gbsuppl6 == ''
        assert gbsuppl7 == ''
        assert sjsuppl8 == ''
        return 'GBSuppl5'
    elif gbsuppl6 != '':
        # assert gbsuppl7 == ''
        assert sjsuppl8 == ''
        if gbsuppl7 != '':
            return gbsuppl6 + 'AndSuppl7'
        return gbsuppl6
    elif gbsuppl7 != '':
        assert sjsuppl8 == ''
        return 'GBSuppl7'
    elif sjsuppl8 != '':
        return 'GBSuppl8'
    if code_range[0] >= 0x4e00 and code_range[1] <= 0x9fa5:
        return 'OtherURO'
    return "Other"

def load_segments():
    gb0_table = load_gb0_table()
    gb1_table = load_gbsuppl1_table()
    gb3_table = load_gbsuppl3_table()
    gb5_table = load_gbsuppl5_table()
    gb6_table = load_gbsupplfictional6_table()
    gb7_table = load_gbsuppl7_table()
    gb8_table = load_sjsuppl8_table()

    merged_table = merge_tables(
        [gb0_table, gb1_table, gb3_table, gb5_table, gb6_table, gb7_table, gb8_table],
        make_gbset_name)
    return merged_table


def emit_util_mod(f):
    f.write("""
pub mod util {
    use core::result::Result::{Ok, Err};

    pub fn bsearch_range_value_table<T: Copy>(c: usize, r: &'static [(usize, usize, T)]) -> Option<T> {
        use core::cmp::Ordering::{Equal, Less, Greater};
        match r.binary_search_by(|&(lo, hi, _)| {
            if lo <= c && c <= hi { Equal }
            else if hi < c { Less }
            else { Greater }
        }) {
            Ok(idx) => {
                let (_, _, cat) = r[idx];
                Some(cat)
            }
            Err(_) => None
        }
    }

}

""")


def format_table_content(f, content, indent):
    line = " "*indent
    first = True
    for chunk in content.split(","):
        if len(line) + len(chunk) < 98:
            if first:
                line += chunk
            else:
                line += ", " + chunk
            first = False
        else:
            f.write(line + ",\n")
            line = " "*indent + chunk
    f.write(line)

def escape_codepoint(c):
    return "0x%04X" % c

def emit_table(f, name, t_data, t_type = "&'static [(usize, usize)]", is_pub=True,
        pfun=lambda x: "(%s,%s)" % (escape_codepoint(x[0]), escape_codepoint(x[1])), is_const=True):
    pub_string = "const"
    if not is_const:
        pub_string = "let"
    if is_pub:
        pub_string = "pub " + pub_string
    f.write("    %s %s: %s = &[\n" % (pub_string, name, t_type))
    data = ""
    first = True
    for dat in t_data:
        if not first:
            data += ","
        first = False
        data += pfun(dat)
    format_table_content(f, data, 8)
    f.write("\n    ];\n\n")

def emit_gbset_data(f, segments):
    f.write("""
pub mod gbset_data {
    #[derive(Copy, Clone, Hash, Eq, PartialEq, Ord, PartialOrd, Debug)]
    #[allow(non_camel_case_types)]
    pub enum GBSet {
        GB0L1,
        GB0L1AndSuppl1,
        GB0L1AndSuppl3,
        GB0L2,
        GB0L2AndSuppl1,
        GBSuppl1,
        GBSuppl3,
        GBSuppl5,
        GBSupplFictional6G7,
        GBSupplFictional6G8,
        GBSupplFictional6GU,
        GBSupplFictional6GK,
        GBSupplFictional6GH,
        GBSupplFictional6GT,
        GBSupplFictional6GHZ,
        GBSuppl7,
        GBSuppl8,
        Other,
    }

    #[inline]
    pub fn gbset_data_lookup(c: char) -> GBSet {
        // FIXME: do we want to special case ASCII here?
        match c as usize {
            _ => super::util::bsearch_range_value_table(c as usize, GBSET_LIST).unwrap()
        }
    }

""")
    emit_table(f, "GBSET_LIST", segments, "&'static [(usize, usize, GBSet)]", is_pub=False,
            pfun=lambda x: "(%s,%s, GBSet::%s)" % (escape_codepoint(x[0][0]), escape_codepoint(x[0][1]), x[1]))
    f.write("}\n\n")

if __name__ == "__main__":
    r = "src/tables.rs"
    if os.path.exists(r):
        os.remove(r)
    with open(r, "w") as rf:
        # write the file's preamble
        rf.write(preamble)

        rf.write("""
/// The version of [Unicode](http://www.unicode.org/)
/// that this version of `unicode-gbset` is based on.
pub const UNICODE_VERSION: (u64, u64, u64) = (%s, %s, %s);

""" % UNICODE_VERSION)
        segments = load_segments()
        emit_util_mod(rf)
        emit_gbset_data(rf, segments)
